import streamlit as st
import whisper
import os
import tempfile
from pathlib import Path
import time

# Page configuration
st.set_page_config(
    page_title="Whisper è¯­éŸ³è½¬æ–‡å­—",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# Title and description
st.title("ğŸ™ï¸ Whisper è¯­éŸ³è½¬æ–‡å­— Web ç•Œé¢")
st.markdown("""
è¿™æ˜¯ä¸€ä¸ªåŸºäº OpenAI Whisper çš„è¯­éŸ³è¯†åˆ« Web åº”ç”¨ã€‚æ”¯æŒå¤šè¯­è¨€è¯­éŸ³è½¬å½•å’Œç¿»è¯‘åŠŸèƒ½ã€‚
""")

# Sidebar for settings
st.sidebar.header("âš™ï¸ è®¾ç½®")

# Model selection
model_options = ["tiny", "base", "small", "medium", "large", "turbo",
                 "tiny.en", "base.en", "small.en", "medium.en"]
selected_model = st.sidebar.selectbox(
    "é€‰æ‹©æ¨¡å‹",
    model_options,
    index=5,  # Default to turbo
    help="è¾ƒå¤§çš„æ¨¡å‹æ›´å‡†ç¡®ä½†é€Ÿåº¦è¾ƒæ…¢ã€‚'turbo' æ¨¡å‹æä¾›æœ€ä½³çš„é€Ÿåº¦å’Œå‡†ç¡®æ€§å¹³è¡¡ã€‚"
)

# Task selection
task_options = ["transcribe", "translate"]
selected_task = st.sidebar.selectbox(
    "é€‰æ‹©ä»»åŠ¡",
    task_options,
    help="transcribe: è½¬å½•åŸè¯­è¨€\ntranslate: ç¿»è¯‘æˆè‹±æ–‡ï¼ˆæ³¨æ„ï¼šturbo æ¨¡å‹ä¸æ”¯æŒç¿»è¯‘ï¼‰"
)

# Language selection
languages = {
    "è‡ªåŠ¨æ£€æµ‹": None,
    "ä¸­æ–‡": "Chinese",
    "è‹±æ–‡": "English",
    "æ—¥è¯­": "Japanese",
    "éŸ©è¯­": "Korean",
    "è¥¿ç­ç‰™è¯­": "Spanish",
    "æ³•è¯­": "French",
    "å¾·è¯­": "German",
    "ä¿„è¯­": "Russian",
    "é˜¿æ‹‰ä¼¯è¯­": "Arabic",
    "è‘¡è„ç‰™è¯­": "Portuguese",
    "æ„å¤§åˆ©è¯­": "Italian"
}

selected_language = st.sidebar.selectbox(
    "è¯­è¨€",
    list(languages.keys()),
    help="æŒ‡å®šéŸ³é¢‘çš„è¯­è¨€ï¼Œæˆ–é€‰æ‹©'è‡ªåŠ¨æ£€æµ‹'"
)

# Advanced options
with st.sidebar.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
    temperature = st.slider("Temperature", 0.0, 1.0, 0.0, 0.1,
                           help="é‡‡æ ·æ¸©åº¦ï¼Œè¾ƒé«˜çš„å€¼ä¼šå¢åŠ éšæœºæ€§")
    beam_size = st.number_input("Beam Size", 1, 10, 5,
                                help="æŸæœç´¢çš„å¤§å°ï¼Œè¾ƒå¤§çš„å€¼å¯èƒ½æé«˜å‡†ç¡®æ€§ä½†é€Ÿåº¦è¾ƒæ…¢")
    best_of = st.number_input("Best Of", 1, 10, 5,
                              help="ä»å¤šå°‘ä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€ä½³ç»“æœ")

# Warning for turbo model and translation
if selected_model == "turbo" and selected_task == "translate":
    st.sidebar.warning("âš ï¸ 'turbo' æ¨¡å‹ä¸æ”¯æŒç¿»è¯‘ä»»åŠ¡ã€‚è¯·é€‰æ‹©å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ medium æˆ– largeï¼‰ä»¥è¿›è¡Œç¿»è¯‘ã€‚")

# Model loading status
@st.cache_resource
def load_whisper_model(model_name):
    """Load and cache the Whisper model"""
    with st.spinner(f"æ­£åœ¨åŠ è½½ {model_name} æ¨¡å‹..."):
        model = whisper.load_model(model_name)
    return model

# Main content area
st.header("ğŸ“¤ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶")

# File uploader
uploaded_file = st.file_uploader(
    "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
    type=["mp3", "mp4", "wav", "m4a", "flac", "ogg", "webm"],
    help="æ”¯æŒå¸¸è§çš„éŸ³é¢‘å’Œè§†é¢‘æ ¼å¼"
)

# Audio recording option
st.markdown("---")
st.subheader("ğŸ¤ æˆ–è€…å½•åˆ¶éŸ³é¢‘")
st.info("æµè§ˆå™¨å½•éŸ³åŠŸèƒ½éœ€è¦ HTTPS æˆ– localhost ç¯å¢ƒã€‚")

# Process button
if uploaded_file is not None:
    # Display audio player
    st.audio(uploaded_file)

    # Show file info
    file_details = {
        "æ–‡ä»¶å": uploaded_file.name,
        "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024:.2f} KB",
        "æ–‡ä»¶ç±»å‹": uploaded_file.type
    }

    with st.expander("ğŸ“‹ æ–‡ä»¶ä¿¡æ¯"):
        for key, value in file_details.items():
            st.write(f"**{key}:** {value}")

    st.markdown("---")

    # Process button
    if st.button("ğŸš€ å¼€å§‹è½¬å½•", type="primary", use_container_width=True):
        try:
            # Create temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name

            # Load model
            model = load_whisper_model(selected_model)

            # Prepare transcription options
            transcribe_options = {
                "task": selected_task,
                "temperature": temperature,
                "beam_size": beam_size,
                "best_of": best_of
            }

            # Add language if specified
            if languages[selected_language] is not None:
                transcribe_options["language"] = languages[selected_language]

            # Progress bar
            progress_bar = st.progress(0)
            status_text = st.empty()

            # Start transcription
            status_text.text("æ­£åœ¨å¤„ç†éŸ³é¢‘æ–‡ä»¶...")
            progress_bar.progress(30)

            start_time = time.time()
            result = model.transcribe(tmp_file_path, **transcribe_options)
            end_time = time.time()

            progress_bar.progress(100)
            status_text.text("è½¬å½•å®Œæˆï¼")

            # Display results
            st.success(f"âœ… è½¬å½•å®Œæˆï¼ç”¨æ—¶: {end_time - start_time:.2f} ç§’")

            # Detected language
            if "language" in result:
                st.info(f"ğŸŒ æ£€æµ‹åˆ°çš„è¯­è¨€: {result['language'].upper()}")

            # Transcription text
            st.subheader("ğŸ“ è½¬å½•ç»“æœ")
            st.text_area(
                "æ–‡æœ¬å†…å®¹",
                result["text"],
                height=300,
                help="æ‚¨å¯ä»¥å¤åˆ¶æ­¤æ–‡æœ¬"
            )

            # Download button for text
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½æ–‡æœ¬æ–‡ä»¶",
                data=result["text"],
                file_name=f"{Path(uploaded_file.name).stem}_transcription.txt",
                mime="text/plain"
            )

            # Show segments if available
            if "segments" in result and len(result["segments"]) > 0:
                with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†åˆ†æ®µ"):
                    for i, segment in enumerate(result["segments"]):
                        st.markdown(f"""
                        **åˆ†æ®µ {i+1}**
                        - æ—¶é—´: {segment['start']:.2f}s - {segment['end']:.2f}s
                        - æ–‡æœ¬: {segment['text']}
                        """)

            # Clean up temporary file
            os.unlink(tmp_file_path)

        except Exception as e:
            st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
                os.unlink(tmp_file_path)

else:
    st.info("ğŸ‘† è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶å¼€å§‹ä½¿ç”¨")

# Footer with information
st.markdown("---")
with st.expander("â„¹ï¸ å…³äº Whisper æ¨¡å‹"):
    st.markdown("""
    ### å¯ç”¨æ¨¡å‹

    | æ¨¡å‹ | å‚æ•° | æ‰€éœ€æ˜¾å­˜ | ç›¸å¯¹é€Ÿåº¦ | è¯´æ˜ |
    |------|------|---------|---------|------|
    | tiny | 39M | ~1 GB | ~10x | æœ€å¿«ä½†å‡†ç¡®åº¦è¾ƒä½ |
    | base | 74M | ~1 GB | ~7x | å¿«é€Ÿä¸”è½»é‡ |
    | small | 244M | ~2 GB | ~4x | è‰¯å¥½çš„é€Ÿåº¦å’Œå‡†ç¡®åº¦å¹³è¡¡ |
    | medium | 769M | ~5 GB | ~2x | è¾ƒé«˜å‡†ç¡®åº¦ |
    | large | 1550M | ~10 GB | 1x | æœ€é«˜å‡†ç¡®åº¦ |
    | turbo | 809M | ~6 GB | ~8x | æ¨èï¼šé€Ÿåº¦å¿«ä¸”å‡†ç¡®åº¦é«˜ |

    **æ³¨æ„:**
    - `.en` åç¼€çš„æ¨¡å‹ä»…æ”¯æŒè‹±è¯­ï¼Œä½†åœ¨è‹±è¯­è¯†åˆ«ä¸Šè¡¨ç°æ›´å¥½
    - `turbo` æ¨¡å‹ä¸æ”¯æŒç¿»è¯‘ä»»åŠ¡
    - ç¿»è¯‘ä»»åŠ¡è¯·ä½¿ç”¨ `medium` æˆ– `large` æ¨¡å‹

    ### æ”¯æŒçš„è¯­è¨€
    Whisper æ”¯æŒ 99 ç§è¯­è¨€çš„è½¬å½•å’Œç¿»è¯‘ã€‚

    ### äº†è§£æ›´å¤š
    - [Whisper é¡¹ç›®ä¸»é¡µ](https://github.com/openai/whisper)
    - [æŠ€æœ¯è®ºæ–‡](https://arxiv.org/abs/2212.04356)
    - [OpenAI åšå®¢](https://openai.com/blog/whisper)
    """)

st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>Powered by <a href='https://github.com/openai/whisper'>OpenAI Whisper</a> | Built with <a href='https://streamlit.io'>Streamlit</a></p>
</div>
""", unsafe_allow_html=True)
